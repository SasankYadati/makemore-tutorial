{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emma'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a trigram is split as follows, x is the input to NN, and y is the expected o/p\n",
    "x = [('.','.'), ('.', 'e')]\n",
    "y = ['e', 'm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper dictionary\n",
    "stoi = {s:i+1 for i,s in enumerate(sorted(list(set(''.join(words)))))}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we can't pass the characters as is, we will one hot encode inputs and expected outputs\n",
    "# say we have N examples\n",
    "# x will have shape (2,27) , each row representing each character in the input bigram\n",
    "# xs will have shape (N, 2, 27), each row representing each example\n",
    "# output will be of shape (N, 27), each row is a probability distribution of last character in the trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([260179, 27])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for w in words[:]:\n",
    "    chs = ['.','.'] + list(w) + ['.', '.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        x = torch.zeros(27).float()\n",
    "        x[stoi[ch1]] += 1\n",
    "        x[stoi[ch2]] += 1\n",
    "        xs.append(x)\n",
    "        ys.append(stoi[ch3])\n",
    "xenc = torch.stack(xs)\n",
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([260179, 27])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need a weight matrix that takes \n",
    "# [N, 2, 27] to [N, 27]\n",
    "W = torch.randn((27,27), requires_grad=True)\n",
    "(xenc @ W).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5456, grad_fn=<AddBackward0>)\n",
      "tensor(4.2396, grad_fn=<AddBackward0>)\n",
      "tensor(3.9882, grad_fn=<AddBackward0>)\n",
      "tensor(3.7883, grad_fn=<AddBackward0>)\n",
      "tensor(3.6458, grad_fn=<AddBackward0>)\n",
      "tensor(3.5442, grad_fn=<AddBackward0>)\n",
      "tensor(3.4626, grad_fn=<AddBackward0>)\n",
      "tensor(3.3943, grad_fn=<AddBackward0>)\n",
      "tensor(3.3364, grad_fn=<AddBackward0>)\n",
      "tensor(3.2867, grad_fn=<AddBackward0>)\n",
      "tensor(3.2433, grad_fn=<AddBackward0>)\n",
      "tensor(3.2047, grad_fn=<AddBackward0>)\n",
      "tensor(3.1699, grad_fn=<AddBackward0>)\n",
      "tensor(3.1383, grad_fn=<AddBackward0>)\n",
      "tensor(3.1093, grad_fn=<AddBackward0>)\n",
      "tensor(3.0825, grad_fn=<AddBackward0>)\n",
      "tensor(3.0577, grad_fn=<AddBackward0>)\n",
      "tensor(3.0347, grad_fn=<AddBackward0>)\n",
      "tensor(3.0133, grad_fn=<AddBackward0>)\n",
      "tensor(2.9934, grad_fn=<AddBackward0>)\n",
      "tensor(2.9748, grad_fn=<AddBackward0>)\n",
      "tensor(2.9574, grad_fn=<AddBackward0>)\n",
      "tensor(2.9411, grad_fn=<AddBackward0>)\n",
      "tensor(2.9258, grad_fn=<AddBackward0>)\n",
      "tensor(2.9114, grad_fn=<AddBackward0>)\n",
      "tensor(2.8978, grad_fn=<AddBackward0>)\n",
      "tensor(2.8851, grad_fn=<AddBackward0>)\n",
      "tensor(2.8730, grad_fn=<AddBackward0>)\n",
      "tensor(2.8616, grad_fn=<AddBackward0>)\n",
      "tensor(2.8508, grad_fn=<AddBackward0>)\n",
      "tensor(2.8406, grad_fn=<AddBackward0>)\n",
      "tensor(2.8308, grad_fn=<AddBackward0>)\n",
      "tensor(2.8215, grad_fn=<AddBackward0>)\n",
      "tensor(2.8127, grad_fn=<AddBackward0>)\n",
      "tensor(2.8043, grad_fn=<AddBackward0>)\n",
      "tensor(2.7962, grad_fn=<AddBackward0>)\n",
      "tensor(2.7885, grad_fn=<AddBackward0>)\n",
      "tensor(2.7811, grad_fn=<AddBackward0>)\n",
      "tensor(2.7741, grad_fn=<AddBackward0>)\n",
      "tensor(2.7673, grad_fn=<AddBackward0>)\n",
      "tensor(2.7608, grad_fn=<AddBackward0>)\n",
      "tensor(2.7545, grad_fn=<AddBackward0>)\n",
      "tensor(2.7485, grad_fn=<AddBackward0>)\n",
      "tensor(2.7427, grad_fn=<AddBackward0>)\n",
      "tensor(2.7372, grad_fn=<AddBackward0>)\n",
      "tensor(2.7318, grad_fn=<AddBackward0>)\n",
      "tensor(2.7266, grad_fn=<AddBackward0>)\n",
      "tensor(2.7216, grad_fn=<AddBackward0>)\n",
      "tensor(2.7168, grad_fn=<AddBackward0>)\n",
      "tensor(2.7121, grad_fn=<AddBackward0>)\n",
      "tensor(2.7076, grad_fn=<AddBackward0>)\n",
      "tensor(2.7032, grad_fn=<AddBackward0>)\n",
      "tensor(2.6990, grad_fn=<AddBackward0>)\n",
      "tensor(2.6949, grad_fn=<AddBackward0>)\n",
      "tensor(2.6910, grad_fn=<AddBackward0>)\n",
      "tensor(2.6871, grad_fn=<AddBackward0>)\n",
      "tensor(2.6834, grad_fn=<AddBackward0>)\n",
      "tensor(2.6798, grad_fn=<AddBackward0>)\n",
      "tensor(2.6763, grad_fn=<AddBackward0>)\n",
      "tensor(2.6729, grad_fn=<AddBackward0>)\n",
      "tensor(2.6696, grad_fn=<AddBackward0>)\n",
      "tensor(2.6663, grad_fn=<AddBackward0>)\n",
      "tensor(2.6632, grad_fn=<AddBackward0>)\n",
      "tensor(2.6602, grad_fn=<AddBackward0>)\n",
      "tensor(2.6572, grad_fn=<AddBackward0>)\n",
      "tensor(2.6543, grad_fn=<AddBackward0>)\n",
      "tensor(2.6515, grad_fn=<AddBackward0>)\n",
      "tensor(2.6488, grad_fn=<AddBackward0>)\n",
      "tensor(2.6461, grad_fn=<AddBackward0>)\n",
      "tensor(2.6435, grad_fn=<AddBackward0>)\n",
      "tensor(2.6410, grad_fn=<AddBackward0>)\n",
      "tensor(2.6385, grad_fn=<AddBackward0>)\n",
      "tensor(2.6361, grad_fn=<AddBackward0>)\n",
      "tensor(2.6338, grad_fn=<AddBackward0>)\n",
      "tensor(2.6315, grad_fn=<AddBackward0>)\n",
      "tensor(2.6293, grad_fn=<AddBackward0>)\n",
      "tensor(2.6271, grad_fn=<AddBackward0>)\n",
      "tensor(2.6249, grad_fn=<AddBackward0>)\n",
      "tensor(2.6229, grad_fn=<AddBackward0>)\n",
      "tensor(2.6208, grad_fn=<AddBackward0>)\n",
      "tensor(2.6188, grad_fn=<AddBackward0>)\n",
      "tensor(2.6169, grad_fn=<AddBackward0>)\n",
      "tensor(2.6150, grad_fn=<AddBackward0>)\n",
      "tensor(2.6131, grad_fn=<AddBackward0>)\n",
      "tensor(2.6113, grad_fn=<AddBackward0>)\n",
      "tensor(2.6095, grad_fn=<AddBackward0>)\n",
      "tensor(2.6077, grad_fn=<AddBackward0>)\n",
      "tensor(2.6060, grad_fn=<AddBackward0>)\n",
      "tensor(2.6043, grad_fn=<AddBackward0>)\n",
      "tensor(2.6027, grad_fn=<AddBackward0>)\n",
      "tensor(2.6011, grad_fn=<AddBackward0>)\n",
      "tensor(2.5995, grad_fn=<AddBackward0>)\n",
      "tensor(2.5980, grad_fn=<AddBackward0>)\n",
      "tensor(2.5964, grad_fn=<AddBackward0>)\n",
      "tensor(2.5950, grad_fn=<AddBackward0>)\n",
      "tensor(2.5935, grad_fn=<AddBackward0>)\n",
      "tensor(2.5921, grad_fn=<AddBackward0>)\n",
      "tensor(2.5907, grad_fn=<AddBackward0>)\n",
      "tensor(2.5893, grad_fn=<AddBackward0>)\n",
      "tensor(2.5880, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = torch.stack(xs)\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    loss = -probs[torch.arange(num_examples), ys].log().mean()\n",
    "    loss += 0.1*(W**2).mean() # regularization loss\n",
    "    print(loss)\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -5 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zen.\n",
      "ahi.\n",
      "slabyrealn.\n",
      "tpnu.\n",
      "moan.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    out = []\n",
    "    ix1 = 0\n",
    "    ix2 = 0\n",
    "    while True:\n",
    "        x1 = torch.zeros(1,27)\n",
    "        x1[0, ix1] += 1\n",
    "        x1[0, ix2] += 1\n",
    "        logits =  x1 @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdim=True)\n",
    "        ix3 = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        out.append(itos[ix3])\n",
    "        if ix3 == 0:\n",
    "            break\n",
    "        ix1, ix2 = ix2, ix3\n",
    "    print(''.join(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
