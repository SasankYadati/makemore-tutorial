{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training set of bigrams\n",
    "# we feed each bigram as an input output pair to the NN.\n",
    "xs, ys = [], []\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will one hot encode these integers (which represent indices of chars)\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a308ae3e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1710, -0.9591, -1.9194, -2.6381, -0.6938,  2.6133,  1.0220,  1.1335,\n",
       "         -0.4362,  0.5572,  0.6272, -0.0836, -0.3761,  0.7213,  0.5915, -0.6616,\n",
       "         -0.8417, -0.7701,  1.4991,  0.8957, -0.1696, -0.6707, -0.8702,  0.9211,\n",
       "          0.3527, -2.5752,  0.2264],\n",
       "        [ 0.1107,  1.8776,  0.0739,  1.1788,  0.9717,  0.5884,  0.1451, -0.2949,\n",
       "          1.0429,  0.1200, -2.2544, -1.0316, -0.4569,  1.6050,  1.0165,  1.5315,\n",
       "         -1.0418,  0.6204, -1.7400,  1.0485, -0.4515,  0.2985,  0.5242, -0.6956,\n",
       "         -1.4719, -0.3318, -0.4830],\n",
       "        [ 1.4645, -1.4298, -0.4673, -0.9595, -0.2543, -0.0315, -1.0572, -1.6244,\n",
       "          0.4362, -1.2856, -0.4076,  0.0608, -0.0939, -0.6835, -0.4885, -0.1230,\n",
       "          0.1918, -1.1328,  1.0115,  1.8218, -0.4205, -0.4035, -2.0002,  1.5929,\n",
       "          0.8167,  0.5298, -1.9825],\n",
       "        [ 1.4645, -1.4298, -0.4673, -0.9595, -0.2543, -0.0315, -1.0572, -1.6244,\n",
       "          0.4362, -1.2856, -0.4076,  0.0608, -0.0939, -0.6835, -0.4885, -0.1230,\n",
       "          0.1918, -1.1328,  1.0115,  1.8218, -0.4205, -0.4035, -2.0002,  1.5929,\n",
       "          0.8167,  0.5298, -1.9825],\n",
       "        [ 0.2254,  0.1152,  0.1536,  0.8782,  0.7444,  0.9997, -0.0907,  0.4521,\n",
       "         -1.0560, -0.0285,  1.7727,  0.2370, -0.7399,  1.0590,  1.3011, -0.2616,\n",
       "          1.5819,  1.2132, -0.2572, -0.1469,  1.4179,  0.3833,  1.3719, -0.2098,\n",
       "          1.7569, -1.8391, -0.1260]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((27,27), requires_grad=True)\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0067, 0.0083, 0.0032, 0.0016, 0.0109, 0.2963, 0.0603, 0.0675, 0.0140,\n",
       "         0.0379, 0.0407, 0.0200, 0.0149, 0.0447, 0.0392, 0.0112, 0.0094, 0.0101,\n",
       "         0.0972, 0.0532, 0.0183, 0.0111, 0.0091, 0.0546, 0.0309, 0.0017, 0.0272],\n",
       "        [0.0239, 0.1399, 0.0230, 0.0696, 0.0565, 0.0385, 0.0247, 0.0159, 0.0607,\n",
       "         0.0241, 0.0022, 0.0076, 0.0136, 0.1065, 0.0591, 0.0990, 0.0076, 0.0398,\n",
       "         0.0038, 0.0611, 0.0136, 0.0288, 0.0361, 0.0107, 0.0049, 0.0154, 0.0132],\n",
       "        [0.1226, 0.0068, 0.0178, 0.0109, 0.0220, 0.0275, 0.0099, 0.0056, 0.0439,\n",
       "         0.0078, 0.0189, 0.0301, 0.0258, 0.0143, 0.0174, 0.0251, 0.0343, 0.0091,\n",
       "         0.0780, 0.1753, 0.0186, 0.0189, 0.0038, 0.1394, 0.0642, 0.0482, 0.0039],\n",
       "        [0.1226, 0.0068, 0.0178, 0.0109, 0.0220, 0.0275, 0.0099, 0.0056, 0.0439,\n",
       "         0.0078, 0.0189, 0.0301, 0.0258, 0.0143, 0.0174, 0.0251, 0.0343, 0.0091,\n",
       "         0.0780, 0.1753, 0.0186, 0.0189, 0.0038, 0.1394, 0.0642, 0.0482, 0.0039],\n",
       "        [0.0221, 0.0198, 0.0206, 0.0425, 0.0372, 0.0480, 0.0161, 0.0278, 0.0061,\n",
       "         0.0172, 0.1040, 0.0224, 0.0084, 0.0510, 0.0649, 0.0136, 0.0860, 0.0595,\n",
       "         0.0137, 0.0153, 0.0730, 0.0259, 0.0697, 0.0143, 0.1024, 0.0028, 0.0156]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = (xenc @ W) # log counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram 0 - .e\n",
      "input 0\n",
      "expected o/p index 5, p(5)=0.2962716519832611\n",
      "Bigram 1 - em\n",
      "input 5\n",
      "expected o/p index 13, p(13)=0.10652654618024826\n",
      "Bigram 2 - mm\n",
      "input 13\n",
      "expected o/p index 13, p(13)=0.014313177205622196\n",
      "Bigram 3 - ma\n",
      "input 13\n",
      "expected o/p index 1, p(1)=0.006786306854337454\n",
      "Bigram 4 - a.\n",
      "input 1\n",
      "expected o/p index 0, p(0)=0.022142337635159492\n",
      "3.301105499267578\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    x = xs[i].item()\n",
    "    y = ys[i].item()\n",
    "    print(f\"Bigram {i} - {itos[x]}{itos[y]}\")\n",
    "    print(f\"input {x}\")\n",
    "    print(f\"expected o/p index {y}, p({y})={probs[i, y]}\")\n",
    "    logp = torch.log(probs[i, y])\n",
    "    nll = -logp\n",
    "    nlls[i] = nll\n",
    "print(nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num_examples = xs.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27,27), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8735, grad_fn=<AddBackward0>)\n",
      "tensor(3.7787, grad_fn=<AddBackward0>)\n",
      "tensor(3.6987, grad_fn=<AddBackward0>)\n",
      "tensor(3.6290, grad_fn=<AddBackward0>)\n",
      "tensor(3.5674, grad_fn=<AddBackward0>)\n",
      "tensor(3.5119, grad_fn=<AddBackward0>)\n",
      "tensor(3.4615, grad_fn=<AddBackward0>)\n",
      "tensor(3.4153, grad_fn=<AddBackward0>)\n",
      "tensor(3.3727, grad_fn=<AddBackward0>)\n",
      "tensor(3.3332, grad_fn=<AddBackward0>)\n",
      "tensor(3.2964, grad_fn=<AddBackward0>)\n",
      "tensor(3.2621, grad_fn=<AddBackward0>)\n",
      "tensor(3.2301, grad_fn=<AddBackward0>)\n",
      "tensor(3.2002, grad_fn=<AddBackward0>)\n",
      "tensor(3.1722, grad_fn=<AddBackward0>)\n",
      "tensor(3.1460, grad_fn=<AddBackward0>)\n",
      "tensor(3.1214, grad_fn=<AddBackward0>)\n",
      "tensor(3.0984, grad_fn=<AddBackward0>)\n",
      "tensor(3.0768, grad_fn=<AddBackward0>)\n",
      "tensor(3.0565, grad_fn=<AddBackward0>)\n",
      "tensor(3.0374, grad_fn=<AddBackward0>)\n",
      "tensor(3.0194, grad_fn=<AddBackward0>)\n",
      "tensor(3.0025, grad_fn=<AddBackward0>)\n",
      "tensor(2.9866, grad_fn=<AddBackward0>)\n",
      "tensor(2.9716, grad_fn=<AddBackward0>)\n",
      "tensor(2.9574, grad_fn=<AddBackward0>)\n",
      "tensor(2.9440, grad_fn=<AddBackward0>)\n",
      "tensor(2.9314, grad_fn=<AddBackward0>)\n",
      "tensor(2.9195, grad_fn=<AddBackward0>)\n",
      "tensor(2.9082, grad_fn=<AddBackward0>)\n",
      "tensor(2.8975, grad_fn=<AddBackward0>)\n",
      "tensor(2.8873, grad_fn=<AddBackward0>)\n",
      "tensor(2.8777, grad_fn=<AddBackward0>)\n",
      "tensor(2.8686, grad_fn=<AddBackward0>)\n",
      "tensor(2.8599, grad_fn=<AddBackward0>)\n",
      "tensor(2.8517, grad_fn=<AddBackward0>)\n",
      "tensor(2.8439, grad_fn=<AddBackward0>)\n",
      "tensor(2.8364, grad_fn=<AddBackward0>)\n",
      "tensor(2.8293, grad_fn=<AddBackward0>)\n",
      "tensor(2.8225, grad_fn=<AddBackward0>)\n",
      "tensor(2.8160, grad_fn=<AddBackward0>)\n",
      "tensor(2.8098, grad_fn=<AddBackward0>)\n",
      "tensor(2.8039, grad_fn=<AddBackward0>)\n",
      "tensor(2.7983, grad_fn=<AddBackward0>)\n",
      "tensor(2.7928, grad_fn=<AddBackward0>)\n",
      "tensor(2.7876, grad_fn=<AddBackward0>)\n",
      "tensor(2.7826, grad_fn=<AddBackward0>)\n",
      "tensor(2.7779, grad_fn=<AddBackward0>)\n",
      "tensor(2.7733, grad_fn=<AddBackward0>)\n",
      "tensor(2.7688, grad_fn=<AddBackward0>)\n",
      "tensor(2.7646, grad_fn=<AddBackward0>)\n",
      "tensor(2.7605, grad_fn=<AddBackward0>)\n",
      "tensor(2.7565, grad_fn=<AddBackward0>)\n",
      "tensor(2.7527, grad_fn=<AddBackward0>)\n",
      "tensor(2.7490, grad_fn=<AddBackward0>)\n",
      "tensor(2.7455, grad_fn=<AddBackward0>)\n",
      "tensor(2.7421, grad_fn=<AddBackward0>)\n",
      "tensor(2.7387, grad_fn=<AddBackward0>)\n",
      "tensor(2.7355, grad_fn=<AddBackward0>)\n",
      "tensor(2.7324, grad_fn=<AddBackward0>)\n",
      "tensor(2.7294, grad_fn=<AddBackward0>)\n",
      "tensor(2.7265, grad_fn=<AddBackward0>)\n",
      "tensor(2.7236, grad_fn=<AddBackward0>)\n",
      "tensor(2.7209, grad_fn=<AddBackward0>)\n",
      "tensor(2.7182, grad_fn=<AddBackward0>)\n",
      "tensor(2.7156, grad_fn=<AddBackward0>)\n",
      "tensor(2.7131, grad_fn=<AddBackward0>)\n",
      "tensor(2.7106, grad_fn=<AddBackward0>)\n",
      "tensor(2.7083, grad_fn=<AddBackward0>)\n",
      "tensor(2.7059, grad_fn=<AddBackward0>)\n",
      "tensor(2.7037, grad_fn=<AddBackward0>)\n",
      "tensor(2.7015, grad_fn=<AddBackward0>)\n",
      "tensor(2.6993, grad_fn=<AddBackward0>)\n",
      "tensor(2.6973, grad_fn=<AddBackward0>)\n",
      "tensor(2.6952, grad_fn=<AddBackward0>)\n",
      "tensor(2.6932, grad_fn=<AddBackward0>)\n",
      "tensor(2.6913, grad_fn=<AddBackward0>)\n",
      "tensor(2.6894, grad_fn=<AddBackward0>)\n",
      "tensor(2.6876, grad_fn=<AddBackward0>)\n",
      "tensor(2.6858, grad_fn=<AddBackward0>)\n",
      "tensor(2.6841, grad_fn=<AddBackward0>)\n",
      "tensor(2.6824, grad_fn=<AddBackward0>)\n",
      "tensor(2.6807, grad_fn=<AddBackward0>)\n",
      "tensor(2.6791, grad_fn=<AddBackward0>)\n",
      "tensor(2.6775, grad_fn=<AddBackward0>)\n",
      "tensor(2.6759, grad_fn=<AddBackward0>)\n",
      "tensor(2.6744, grad_fn=<AddBackward0>)\n",
      "tensor(2.6729, grad_fn=<AddBackward0>)\n",
      "tensor(2.6715, grad_fn=<AddBackward0>)\n",
      "tensor(2.6701, grad_fn=<AddBackward0>)\n",
      "tensor(2.6687, grad_fn=<AddBackward0>)\n",
      "tensor(2.6673, grad_fn=<AddBackward0>)\n",
      "tensor(2.6660, grad_fn=<AddBackward0>)\n",
      "tensor(2.6647, grad_fn=<AddBackward0>)\n",
      "tensor(2.6634, grad_fn=<AddBackward0>)\n",
      "tensor(2.6622, grad_fn=<AddBackward0>)\n",
      "tensor(2.6610, grad_fn=<AddBackward0>)\n",
      "tensor(2.6598, grad_fn=<AddBackward0>)\n",
      "tensor(2.6587, grad_fn=<AddBackward0>)\n",
      "tensor(2.6575, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    loss = -probs[torch.arange(num_examples), ys].log().mean()\n",
    "    loss += 0.1*(W**2).mean() # regularization loss\n",
    "    print(loss)\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -10 * W.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenn.\n",
      "annka.\n",
      "seeettin.\n",
      "amadonden.\n",
      "a.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits =  xenc @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdim=True)\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
